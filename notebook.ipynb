{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Work Project\n",
    "The goal of this project is to use methods in data science to predict the probability that every player in the first round of the 2019 NBA draft makes an All-NBA team throughout their careers.\n",
    "\n",
    "### Anaconda\n",
    "We will use the Anaconda platform for Python for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# def warn(*args, **kwargs):\n",
    "#     pass\n",
    "\n",
    "# import warnings\n",
    "# warnings.warn = warn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Random Forest\n",
    "\n",
    "oversample = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the data for analysis\n",
    "The data consists of the college basketball statistics of all first round picks who have played in the NCAA, since the 1990 NBA Draft. The columns consist of:\n",
    "* Points per game\n",
    "* Rebounds per game\n",
    "* Assists per game\n",
    "* Steals per game\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Player  Pick #   RPG  APG  SPG  BPG   PPG    SOS    TS%    FTr  \\\n",
      "0     Derrick Coleman       1  12.1  2.9  1.5  2.0  17.9   8.85  0.620  0.747   \n",
      "1         Gary Payton       2   4.7  8.1  3.4  0.5  25.7   6.91  0.572  0.299   \n",
      "2  Mahmoud Abdul-Rauf       3   2.5  3.2  1.6  0.0  27.8   7.61  0.584  0.317   \n",
      "3        Dennis Scott       4   6.6  2.0  1.8  0.9  27.7  10.33  0.593  0.281   \n",
      "4        Kendall Gill       5   4.9  3.3  2.2  0.6  20.0   9.89  0.575  0.415   \n",
      "\n",
      "   Height  Weight  Age  All-NBA  \n",
      "0      82     230   23        1  \n",
      "1      76     180   22        1  \n",
      "2      73     162   21        0  \n",
      "3      80     229   22        0  \n",
      "4      77     195   22        0  \n"
     ]
    }
   ],
   "source": [
    "# Loading data as Pandas dataframe\n",
    "df = pd.read_csv('data.csv', header=0)\n",
    "print(df.head())\n",
    "df = df._get_numeric_data()\n",
    "headers = list(df.columns)\n",
    "\n",
    "dataset = df.to_numpy()\n",
    "\n",
    "y_i = headers.index('All-NBA')\n",
    "    \n",
    "# Separate data into features and target\n",
    "x = dataset[:, 0:y_i]\n",
    "y = dataset[:, y_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset: (333, 12)\n",
      "Shape of testing dataset: (112, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, stratify=y, random_state=0)\n",
    "\n",
    "if oversample:\n",
    "    sm = SMOTE()\n",
    "    x_train, y_train = sm.fit_sample(x_train, y_train.ravel())\n",
    "\n",
    "print('Shape of training dataset:', x_train.shape)\n",
    "print('Shape of testing dataset:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Models\n",
    "We will use the following models for the following reasons...\n",
    "\n",
    "## 1. Logistic Regression Model\n",
    "Our first model will be a logistic regression model, using the default sklearn parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-436-e623d49f8179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m param_grid = [\n\u001b[0;32m     11\u001b[0m     {\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;34m'reduce_dim'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#         'reduce_dim__n_components': features,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;34m'LOG__solver'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'estimator'"
     ]
    }
   ],
   "source": [
    "log_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('LOG', LogisticRegression())\n",
    "])\n",
    "\n",
    "features = [2, 4, 8]\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), RFE(LogisticRegression())],\n",
    "#         'reduce_dim__n_components': features,\n",
    "        'LOG__solver': ['liblinear'],\n",
    "        'LOG__penalty': ['l1','l2'],\n",
    "        'LOG__C': C\n",
    "    }\n",
    "#     {\n",
    "#         'reduce_dim': [SelectKBest(chi2)],\n",
    "#         'reduce_dim__k': features,\n",
    "#         'LOG__solver': ['liblinear'],\n",
    "#         'LOG__penalty': ['l1','l2'],\n",
    "#         'LOG__C': C\n",
    "#     },\n",
    "]\n",
    "\n",
    "model_log = GridSearchCV(log_pipeline, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('RFC', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "grid_values = {\n",
    "    'RFC__max_features': ['auto', 'sqrt'],\n",
    "    'RFC__max_depth': [5, 10, 15, 20],\n",
    "    'RFC__n_estimators': [80, 90, 100, 110, 120]\n",
    "}\n",
    "\n",
    "model_rfc = GridSearchCV(rfc_pipeline, param_grid=grid_values, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Models\n",
    "We will now look at a few methods of evaluating the models we've created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation method\n",
    "def evaluate(model, model_name):\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # Accuracy, recall, precision and F1\n",
    "    print('Accuracy of \"%s\" model: %.3f' % (model_name, metrics.accuracy_score(y_test, pred)))\n",
    "    print('Recall of \"%s\" model: %.3f' % (model_name, metrics.recall_score(y_test, pred)))\n",
    "    print('Precision of \"%s\" model: %.3f' % (model_name, metrics.precision_score(y_test, pred)))\n",
    "    print('F1 of \"%s\" model: %.3f' % (model_name, metrics.f1_score(y_test, pred)))\n",
    "\n",
    "    # Confusion matrix\n",
    "    xlabels=['Predicted 0', 'Predicted 1']\n",
    "    ylabels=['Actual 0', 'Actual 1']\n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    ax = sn.heatmap(df_cm, square=True, annot=True, xticklabels=xlabels, yticklabels=ylabels)\n",
    "    ax.set_ylim(2, 0) # workaround for cut-off bug\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    probs = model.predict_proba(x_test)[:,1]\n",
    "    fpr, tpr, threshold = roc_curve(y_test, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic - %s' % model_name)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier\n",
    "A dummy classifier assigns labels randomly, according to the distribution of classes in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy='stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dummy, 'Dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_log, 'Logistic Regression')\n",
    "print(model_log.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_rfc, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on 2019 Rookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data as Pandas dataframe\n",
    "df = pd.read_csv('rookies.csv', header=0)\n",
    "stats = df._get_numeric_data()\n",
    "rookies = stats.to_numpy()\n",
    "\n",
    "def pred_rookies(model, model_name):\n",
    "    pred = model.predict_proba(rookies)\n",
    "\n",
    "    print('Predicted probabilities (%s)' % model_name)\n",
    "    print('==================================')\n",
    "    for i in range(len(pred)):\n",
    "        print('%-28s %.3f ' % (df['Player'][i], pred[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rookies(model_log, \"Logistic\")\n",
    "pred_rookies(model_rfc, \"RFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
